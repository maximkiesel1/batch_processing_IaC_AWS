{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b3612a",
   "metadata": {},
   "source": [
    "# Demo Transformationsskript AWS Glue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece627a5",
   "metadata": {},
   "source": [
    "This demo shows how the transformation skript for AWS Glue is working. \n",
    "The goal of the skript is to transform the given data to a timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa4f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, posexplode, expr,when\n",
    "\n",
    "# Start PySpark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSV Transformation\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the data\n",
    "df = spark.read.csv(\n",
    "    '/Users/maximkiesel/batch_processing_IaC_AWS/data/20230703_measurement_data.csv',\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# Sorting the data by 'start_time' ascending\n",
    "sorted_df = df.orderBy(col(\"start_time\").asc())\n",
    "\n",
    "# Calculate the time delta per sample\n",
    "sorted_df = sorted_df.withColumn(\n",
    "    \"timedelta_per_sample\",\n",
    "    when(col(\"samples\").isNotNull() & (col(\"samples\") != 0),\n",
    "         (col(\"end_time\") - col(\"start_time\")) / col(\"samples\")).otherwise(expr(\"INTERVAL 0 SECONDS\"))\n",
    ")\n",
    "\n",
    "# Generate an array of integers from 0 to the maximum number of samples minus 1\n",
    "df_expanded = sorted_df.withColumn(\n",
    "    \"idx_array\",\n",
    "    expr(\"sequence(0, samples - 1)\")\n",
    ")\n",
    "\n",
    "# Calculate the expanded start_timestamp and end_timestamp values based on the idx_array column\n",
    "df_expanded = df_expanded.withColumn(\n",
    "    \"expanded_rows\",\n",
    "    expr(\n",
    "        \"\"\"\n",
    "        transform(idx_array, idx -> struct(\n",
    "            start_time + idx * timedelta_per_sample AS start_time,\n",
    "            start_time + (idx + 1) * timedelta_per_sample AS end_time\n",
    "        ))\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop the idx_array column\n",
    "df_expanded = df_expanded.drop(\"idx_array\")\n",
    "\n",
    "\n",
    "# Explode the 'expanded_rows' array column into multiple rows\n",
    "df_explode = df_expanded.select(\"*\", posexplode(\"expanded_rows\").alias(\"index\", \"exploded_timestamps\"))\n",
    "\n",
    "# Extract start_timestamp and end_timestamp from the exploded 'timestamps' struct column\n",
    "df_extracted = df_explode.withColumn(\n",
    "    \"start_time\",\n",
    "    col(\"exploded_timestamps\").getField(\"start_time\")\n",
    ").withColumn(\n",
    "    \"end_time\",\n",
    "    col(\"exploded_timestamps\").getField(\"end_time\")\n",
    ")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"expanded_rows\",\n",
    "    \"index\",\n",
    "#   \"samples\",\n",
    "#    \"timedelta_per_sample\",\n",
    "#    \"exploded_timestamps\"\n",
    "#]\n",
    "#df_extracted = df_extracted.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4084c58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows before the transformation\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a4c8b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " start_time  | 2023-06-26 21:05:00.474245 \n",
      " end_time    | 2023-06-26 21:05:39.474245 \n",
      " measurement | 10.855276688682668         \n",
      " samples     | 10                         \n",
      "-RECORD 1---------------------------------\n",
      " start_time  | 2023-06-26 21:05:39.474245 \n",
      " end_time    | 2023-06-26 21:06:27.474245 \n",
      " measurement | 23.786844986177393         \n",
      " samples     | 6                          \n",
      "-RECORD 2---------------------------------\n",
      " start_time  | 2023-06-26 21:06:27.474245 \n",
      " end_time    | 2023-06-26 21:07:13.474245 \n",
      " measurement | 24.86492949965332          \n",
      " samples     | 7                          \n",
      "-RECORD 3---------------------------------\n",
      " start_time  | 2023-06-26 21:07:13.474245 \n",
      " end_time    | 2023-06-26 21:07:51.474245 \n",
      " measurement | 38.13194561302163          \n",
      " samples     | 10                         \n",
      "-RECORD 4---------------------------------\n",
      " start_time  | 2023-06-26 21:07:51.474245 \n",
      " end_time    | 2023-06-26 21:08:32.474245 \n",
      " measurement | 21.166757357237074         \n",
      " samples     | 12                         \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate= False, vertical= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cdac19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10010137"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows after the transformation\n",
    "df_extracted.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38c3c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_extracted.show(5, truncate= False, vertical= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c595ebc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
